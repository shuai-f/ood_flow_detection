/Users/shuaif/miniforge3/envs/py38/bin/python /Users/shuaif/PycharmProjects/ood_flow_detection/contrast_learning/main_ce_baseline.py --epoch 50 --model RNN --batch_size 128 --n_data_train 260000 --activation relu
Namespace(activation='relu', batch_size=128, data='moore', draw_figures=False, epoch=50, lr=0.0001, model='RNN', n_data_train=260000, projection_dim=128, write_summary=False)
Loading moore data...
(268611, 256) (89538, 256)
Training dataset shapes after slicing:
(260000, 256, 1) (260000,)
2023-03-15 23:00:59.486993: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 240206 of 260000
2023-03-15 23:01:09.486801: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 248449 of 260000
2023-03-15 23:01:19.487583: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 256096 of 260000
2023-03-15 23:01:25.670110: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.
/Users/shuaif/miniforge3/envs/py38/lib/python3.8/site-packages/keras/backend.py:5585: UserWarning: "`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?
  output, from_logits = _get_logits(
2023-03-15 23:01:26.163984: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
Epoch 1, Loss: 0.5443820953369141, Acc: 87.76961517333984, Test Loss: 0.43237143754959106, Test Acc: 89.07726287841797
Epoch 2, Loss: 0.3664437532424927, Acc: 89.97000122070312, Test Loss: 0.2905605137348175, Test Acc: 92.10167694091797
Epoch 3, Loss: 0.26820552349090576, Acc: 92.3923110961914, Test Loss: 0.24501587450504303, Test Acc: 93.2040023803711
Epoch 4, Loss: 0.2829718291759491, Acc: 91.86653900146484, Test Loss: 0.23915918171405792, Test Acc: 93.1939468383789
Epoch 5, Loss: 0.23202644288539886, Acc: 92.91345977783203, Test Loss: 0.1964394897222519, Test Acc: 93.85958862304688
Epoch 6, Loss: 0.20812790095806122, Acc: 93.73384857177734, Test Loss: 0.2089654803276062, Test Acc: 93.14146423339844
Epoch 7, Loss: 0.20311804115772247, Acc: 94.05769348144531, Test Loss: 0.17585769295692444, Test Acc: 95.16741943359375
Epoch 8, Loss: 0.1793578565120697, Acc: 94.9111557006836, Test Loss: 0.16922850906848907, Test Acc: 95.07807159423828
Epoch 9, Loss: 0.14848722517490387, Acc: 95.724609375, Test Loss: 0.13644210994243622, Test Acc: 96.37248992919922
Epoch 10, Loss: 0.15725569427013397, Acc: 95.54769134521484, Test Loss: 0.14586713910102844, Test Acc: 95.8810806274414
Epoch 11, Loss: 0.13963423669338226, Acc: 96.01461029052734, Test Loss: 0.14675273001194, Test Acc: 95.92687225341797
Epoch 12, Loss: 0.12660014629364014, Acc: 96.44499969482422, Test Loss: 0.1287284940481186, Test Acc: 96.44508361816406
Epoch 13, Loss: 0.12670758366584778, Acc: 96.49038696289062, Test Loss: 0.1088046133518219, Test Acc: 97.04035949707031
Epoch 14, Loss: 0.13870051503181458, Acc: 96.09076690673828, Test Loss: 0.1297929286956787, Test Acc: 96.20384216308594
Epoch 15, Loss: 0.12573683261871338, Acc: 96.44307708740234, Test Loss: 0.12643423676490784, Test Acc: 96.46183776855469
Epoch 16, Loss: 0.17012250423431396, Acc: 95.06884765625, Test Loss: 0.13996616005897522, Test Acc: 95.9737777709961
Epoch 17, Loss: 0.12260928750038147, Acc: 96.54153442382812, Test Loss: 0.11415015906095505, Test Acc: 96.70977783203125
Epoch 18, Loss: 0.11570234596729279, Acc: 96.69153594970703, Test Loss: 0.10972151905298233, Test Acc: 96.88512420654297
Epoch 19, Loss: 0.11170413345098495, Acc: 96.8592300415039, Test Loss: 0.11115069687366486, Test Acc: 96.88512420654297
Epoch 20, Loss: 0.10738179087638855, Acc: 96.9511489868164, Test Loss: 0.29514697194099426, Test Acc: 91.5019302368164
Epoch 21, Loss: 0.12214962393045425, Acc: 96.5046157836914, Test Loss: 0.17336328327655792, Test Acc: 94.93399047851562
Epoch 22, Loss: 0.1115996465086937, Acc: 96.87153625488281, Test Loss: 0.11267774552106857, Test Acc: 96.76785278320312
Epoch 23, Loss: 0.09650643169879913, Acc: 97.32422637939453, Test Loss: 0.09678207337856293, Test Acc: 97.37765502929688
Epoch 24, Loss: 0.21169261634349823, Acc: 94.07807922363281, Test Loss: 0.15684066712856293, Test Acc: 95.55496215820312
Epoch 25, Loss: 0.15907439589500427, Acc: 95.48961639404297, Test Loss: 0.13734905421733856, Test Acc: 96.369140625
Epoch 26, Loss: 0.1371055692434311, Acc: 96.15192413330078, Test Loss: 0.12800772488117218, Test Acc: 96.35685729980469
Epoch 27, Loss: 0.12298600375652313, Acc: 96.54923248291016, Test Loss: 0.10753728449344635, Test Acc: 97.20565795898438
Epoch 28, Loss: 0.1140303835272789, Acc: 96.80076599121094, Test Loss: 0.10316785424947739, Test Acc: 97.07833862304688
Epoch 29, Loss: 0.10473226010799408, Acc: 97.03192138671875, Test Loss: 0.09570220112800598, Test Acc: 97.24139404296875
Epoch 30, Loss: 0.09839954227209091, Acc: 97.26192474365234, Test Loss: 0.09520868211984634, Test Acc: 97.38658905029297
Epoch 31, Loss: 0.09601325541734695, Acc: 97.3392333984375, Test Loss: 0.08626143634319305, Test Acc: 97.68701934814453
Epoch 32, Loss: 0.09304890036582947, Acc: 97.40961456298828, Test Loss: 0.08000808954238892, Test Acc: 97.78976440429688
Epoch 33, Loss: 0.09139112383127213, Acc: 97.45769500732422, Test Loss: 0.092855304479599, Test Acc: 97.52172088623047
Epoch 34, Loss: 0.08630521595478058, Acc: 97.5403823852539, Test Loss: 0.08332772552967072, Test Acc: 97.61776733398438
Epoch 35, Loss: 0.08097311854362488, Acc: 97.74115753173828, Test Loss: 0.13939636945724487, Test Acc: 96.35462188720703
Epoch 36, Loss: 0.07970813661813736, Acc: 97.75846099853516, Test Loss: 0.08035724610090256, Test Acc: 97.89698028564453
Epoch 37, Loss: 0.07663553953170776, Acc: 97.84539031982422, Test Loss: 0.07723302394151688, Test Acc: 97.77971649169922
Epoch 38, Loss: 0.0754086971282959, Acc: 97.88230895996094, Test Loss: 0.06724976748228073, Test Acc: 98.15497589111328
Epoch 39, Loss: 0.07188639789819717, Acc: 97.97692108154297, Test Loss: 0.06448843330144882, Test Acc: 98.21192932128906
Epoch 40, Loss: 0.07014282792806625, Acc: 98.03691864013672, Test Loss: 0.061752039939165115, Test Acc: 98.28787994384766
Epoch 41, Loss: 0.06878586113452911, Acc: 98.06922912597656, Test Loss: 0.06400913000106812, Test Acc: 98.28675842285156
Epoch 42, Loss: 0.06637325882911682, Acc: 98.16268920898438, Test Loss: 0.06881988048553467, Test Acc: 98.06897735595703
Epoch 43, Loss: 0.06566935032606125, Acc: 98.20500183105469, Test Loss: 0.06562096625566483, Test Acc: 98.13934326171875
Epoch 44, Loss: 0.06467804312705994, Acc: 98.20269012451172, Test Loss: 0.0675242468714714, Test Acc: 98.19517517089844
Epoch 45, Loss: 0.0740651786327362, Acc: 97.93077087402344, Test Loss: 0.05753257870674133, Test Acc: 98.46321868896484
Epoch 46, Loss: 0.062282100319862366, Acc: 98.3261489868164, Test Loss: 0.05225389823317528, Test Acc: 98.61399841308594
Epoch 47, Loss: 0.05854616314172745, Acc: 98.40077209472656, Test Loss: 0.05518939346075058, Test Acc: 98.52130126953125
Epoch 48, Loss: 0.07848086208105087, Acc: 97.8296127319336, Test Loss: 0.07240821421146393, Test Acc: 97.96734619140625
Epoch 49, Loss: 0.06540992856025696, Acc: 98.1934585571289, Test Loss: 0.05803392827510834, Test Acc: 98.3995590209961
Epoch 50, Loss: 0.056726209819316864, Acc: 98.44999694824219, Test Loss: 0.05396811291575432, Test Acc: 98.53916931152344

Process finished with exit code 137 (interrupted by signal 9: SIGKILL)
